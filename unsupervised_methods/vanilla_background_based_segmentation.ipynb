{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "The key idea of approach is to find background image and subtract it from every frame. The result could be interpreted as segmentation mask."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Loading of video paths"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "outputs": [],
   "source": [
    "vid_dir = \"data/videos\"\n",
    "annotations_dir = \"data/annotations\"\n",
    "vid_paths = []\n",
    "for root, dirs, files in os.walk(vid_dir):\n",
    "    path = root.split(os.sep)\n",
    "    for file in files:\n",
    "        if file.endswith(\".mov\"):\n",
    "            vid_path = os.path.join(root, file)\n",
    "\n",
    "            vid_paths.append(vid_path)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Loading of annotations as well. Annotations represented in pd.DataFrame form. It is necessary to get rid of occluded and lost annotations."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "outputs": [],
   "source": [
    "\n",
    "def read_vid_annotations(vid_path: str) -> pd.DataFrame:\n",
    "    annotation_path = vid_path.replace(\"videos\", \"annotations\")\n",
    "    annotation_path = annotation_path.replace('video.mov', \"annotations.txt\")\n",
    "    df = None\n",
    "    if os.path.exists(annotation_path):\n",
    "        df = pd.read_csv(annotation_path, sep=\" \", header=None,\n",
    "                         names=[\"track\", 'x1', 'y1', 'x2', 'y2', 'frame', 'lost', 'occluded', 'generated', 'label'])\n",
    "    df = df[df[\"lost\"] != 1]\n",
    "    df = df[df[\"occluded\"] != 1]\n",
    "\n",
    "    return df"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Method of background image creation\n",
    "For every frame we create individual background image due to unstable drone position.\n",
    "For every detection (GT bbox) we find the closest frame which doesn't contain overlapping bounding boxes with ours,\n",
    "after that we simply replace bbox are in our frame with same one are from found frame.\n",
    "\n",
    "For search of the closest frame with no overlapping boxes we use the following structure, which utilizes all rectangles from the whole video:"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "outputs": [],
   "source": [
    "class VideoRectangles:\n",
    "    def __init__(self, annot_df: pd.DataFrame, w, h):\n",
    "        self.h = int(h)\n",
    "        self.w = int(w)\n",
    "        self.annot_df = annot_df\n",
    "        self.n_frames = max(annot_df['frame'])\n",
    "        self.xs = [[] for _ in range(self.w)]  # contains list of bbox ids for each x-axis pixel\n",
    "        self.ys = [[] for _ in range(self.h)]  # contains list of bbox ids for each y-axis pixel\n",
    "        self._full_fill_xs_n_ys()\n",
    "\n",
    "    def _full_fill_xs_n_ys(self):\n",
    "        for ind, row in self.annot_df.iterrows():\n",
    "            for i in range(row['x1'], row['x2']):\n",
    "                self.xs[i].append(ind)\n",
    "            for j in range(row['y1'], row['y2']):\n",
    "                self.ys[j].append(ind)\n",
    "\n",
    "    def get_rect_by_id(self, rect_id: int):\n",
    "        return self.annot_df.loc[rect_id]\n",
    "\n",
    "    def get_rects_by_ids(self, rect_ids: int):\n",
    "        return self.annot_df.loc[rect_ids]\n",
    "\n",
    "    def get_rect_ids_for_box(self, x1, y1, x2, y2):\n",
    "        x_rects = set()\n",
    "        for x in range(x1, x2):\n",
    "            x_rects.update(self.xs[x])\n",
    "\n",
    "        y_rects = set()\n",
    "        for y in range(y1, y2):\n",
    "            y_rects.update(self.ys[y])\n",
    "\n",
    "        return x_rects & y_rects\n",
    "\n",
    "    def get_frame_ids_with_intersection_with_box(self, x1, y1, x2, y2):\n",
    "        intersected_rect_ids = self.get_rect_ids_for_box(x1, y1, x2, y2)\n",
    "        tmp_df = self.annot_df[self.annot_df.index.isin(intersected_rect_ids)]\n",
    "        intersected_frame_ids = tmp_df[\"frame\"].unique()\n",
    "        return intersected_frame_ids\n",
    "\n",
    "    def get_frame_ids_without_intersection_with_box(self, x1, y1, x2, y2):\n",
    "        intersected_frame_ids = self.get_frame_ids_with_intersection_with_box(x1, y1, x2, y2)\n",
    "        all_frame_ids = self.annot_df[\"frame\"].unique()\n",
    "\n",
    "        return list(set(all_frame_ids) - set(intersected_frame_ids))\n",
    "\n",
    "    def get_closest_frame_id_without_intersection_with_box(self, cur_frame_id, x1, y1, x2, y2):\n",
    "        all_frame_ids_without_intersection = self.get_frame_ids_without_intersection_with_box(x1, y1, x2, y2)\n",
    "        min_dist = self.n_frames\n",
    "        best_frame_id = None\n",
    "        for other_frame_id in all_frame_ids_without_intersection:\n",
    "            if abs(cur_frame_id - other_frame_id) < min_dist:\n",
    "                min_dist = abs(cur_frame_id - other_frame_id)\n",
    "            best_frame_id = other_frame_id\n",
    "        return best_frame_id"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Define constants and load video"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data/videos/hyang/video5/video.mov\n",
      "num annotation bboxes: 124083\n",
      "num annotation bboxes to process: 9986\n",
      "video length: 10648 res: 1454.0x1991.0 fps: 29.97\n"
     ]
    }
   ],
   "source": [
    "scene_names = [\"bookstore\", \"coupa\",\"deathCircle\",\"gates\",\"hyang\", \"little\", \"nexus\",\"quad\"]\n",
    "val_videos_paths = [os.path.join(vid_dir, scene, \"video0/video.mov\") for scene in scene_names]\n",
    "# to show [0!(hard dark low res), 1(car),4], 5! (car), 8! (large shadow), 11(car), 21!(good quality),26(fence), 31(solid persons), 36 (good quality),\n",
    "# final to show 1(car), 5! (car), 8! (large shadow), 11(car), 21!(good quality),26(fence), 31(solid persons), 36 (good quality)\n",
    "vid_id = 26  # video num to process\n",
    "n_max = 10000  # n first bboxes to process\n",
    "mask_thresh = 40\n",
    "\n",
    "vid_name = vid_paths[vid_id]\n",
    "print(vid_name)\n",
    "\n",
    "annot_df = read_vid_annotations(vid_paths[vid_id])  # read appropriate annotations\n",
    "print(\"num annotation bboxes:\", len(annot_df))\n",
    "\n",
    "annot_df = annot_df.sort_values('frame')\n",
    "annot_df = annot_df.head(n_max)\n",
    "last_frame = annot_df[\"frame\"].max()\n",
    "annot_df = annot_df[annot_df[\"frame\"] != last_frame]\n",
    "print(\"num annotation bboxes to process:\", len(annot_df))\n",
    "\n",
    "vid = cv2.VideoCapture(vid_paths[vid_id])\n",
    "length = int(vid.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "h, w = vid.get(cv2.CAP_PROP_FRAME_WIDTH), vid.get(cv2.CAP_PROP_FRAME_HEIGHT)\n",
    "fps = vid.get(cv2.CAP_PROP_FPS)\n",
    "print(f\"video length: {length} res: {h}x{w} fps: {fps}\")\n",
    "\n",
    "video_rectangles = VideoRectangles(annot_df, h, w)\n",
    "\n",
    "frames = []\n",
    "\n",
    "# preload frames\n",
    "while (1):\n",
    "    ret, frame = vid.read()\n",
    "    if frame is None or len(frames) > max(annot_df[\"frame\"]):\n",
    "        break\n",
    "    frames.append(frame)\n",
    "print(\"num frames to process\", len(frames))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Main loop"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "output_frames = []\n",
    "for i_frame in tqdm(range(len(frames))):\n",
    "    frame = frames[i_frame]\n",
    "    orig_frame = frame[:, :, :]\n",
    "    background_gray = cv2.cvtColor(frame[:, :, :], cv2.COLOR_BGR2GRAY)  #HSV)[:,:,2]\n",
    "\n",
    "    cur_df = annot_df[annot_df[\"frame\"] == i_frame]\n",
    "    for i, row in cur_df.iterrows():\n",
    "        x1, y1, x2, y2 = row[\"x1\"], row['y1'], row[\"x2\"], row['y2']\n",
    "        closest_frame_id = video_rectangles.get_closest_frame_id_without_intersection_with_box(i_frame, x1, y1, x2, y2)\n",
    "        if closest_frame_id is not None:\n",
    "            closest_frame = frames[closest_frame_id]\n",
    "            closest_frame_gray = cv2.cvtColor(closest_frame, cv2.COLOR_BGR2GRAY)  #HSV)[:,:,2]\n",
    "            background_gray[y1:y2, x1:x2] = closest_frame_gray[y1:y2, x1:x2]\n",
    "\n",
    "    mask = abs(cv2.cvtColor(orig_frame, cv2.COLOR_BGR2GRAY).astype(np.int32) - background_gray.astype(np.int32))\n",
    "    # print(\"mask\", mask.dtype, np.min(mask), np.max(mask), np.sum(mask>10),\"/\",np.sum(mask>=0))\n",
    "    mask = cv2.normalize(mask, None, 0, 255, cv2.NORM_MINMAX)\n",
    "    mask[mask <= mask_thresh] = 0\n",
    "\n",
    "    mask[mask > 0] = 1\n",
    "    mask = mask.astype(np.uint8)\n",
    "    segments = np.zeros_like(orig_frame)\n",
    "    segments[:, :, 1] = mask * 255  # green colored mask\n",
    "\n",
    "    res_img = cv2.addWeighted(orig_frame, 0.8, segments, 0.4, 1.0)\n",
    "\n",
    "    for i, row in cur_df.iterrows():\n",
    "        x1, y1, x2, y2 = row[\"x1\"], row['y1'], row[\"x2\"], row['y2']\n",
    "        res_img = cv2.rectangle(res_img, (x1, y1), (x2, y2), (0, 255, 0), 2)\n",
    "\n",
    "    output_frames.append(res_img)\n",
    "    if max(h, w) > 1700:\n",
    "        res_img = cv2.resize(res_img, None, fx=0.6, fy=0.6)\n",
    "    cv2.imshow(vid_name, res_img)\n",
    "    k = cv2.waitKey(30) & 0xff\n",
    "    if k == 27:\n",
    "        break\n",
    "\n",
    "vid.release()\n",
    "cv2.destroyAllWindows()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Write output video"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "out_dir = \"data/output/vanilla_background\"\n",
    "os.makedirs(out_dir, exist_ok=True)\n",
    "out_path = os.path.join(out_dir, vid_name.replace(\"/\", \"_\").replace(\"mov\",\"avi\"))\n",
    "print(out_path, fps, (int(w),int(h)), len(output_frames), output_frames[0].shape)\n",
    "vid_writer = cv2.VideoWriter(out_path, cv2.VideoWriter_fourcc(*'DIVX'), 30,(int(h),int(w)))\n",
    "\n",
    "for frame in output_frames:\n",
    "    vid_writer.write(frame)\n",
    "\n",
    "vid_writer.release()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}