{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Object classes\n",
    "\n",
    "Stanford drone dataset has next object classes: pedestrians, bikers, skateboarders, cars, buses, and golf carts.\n",
    "For drone navigation task it would be useful to reduce number of classes by following rules:\n",
    "pedestrians -> pedestrians; bikers and skateboarders -> bikers; buses, cars and golf carts -> cars, because this aggregated classes represents objects of the similar physical dimensions and moving behavior, what is important for drone navigation planning.\n",
    "\n",
    "So now we have 3 classes: pedestrians, bikers and cars.\n",
    "\n",
    "### Train/val splits\n",
    "\n",
    "It is necessary to have some data for verification.\n",
    "I suggest splitting dataset in train/val in following way:\n",
    "* In every scene bring one video to val split;\n",
    "* Also bring to val one whole scene\n",
    "because dataset itself has low number of scenes which can differ a lot\n",
    "from each other, so we need to check model on completely unseen data.\n",
    "\n",
    "For each val video annotation produced only for last 20 frames using seprvisly.\n",
    "\n",
    "### Stanford dataset analysis\n",
    "Provided in stanford_dataset_overview.ipynb\n",
    "\n",
    "### Segmentation approaches\n",
    "\n",
    "Cause stanford drone dataset has no segmentation annotation we need either to create Unsupervised segmentation annotation for learning/inference purposes\n",
    "or apply pretrained on similar dataset model to our data.\n",
    "\n",
    "Overall I think the following segmentation 3 approaches are worth to be considered:\n",
    "\n",
    "1. <b>Unsupervised segmentation based on background image. </b>\n",
    "Having background image for each clip it is easy get segmentation by subtraction of frames and background, class assignment could be done with help of bounding boxes classes.\n",
    "If camera position was static, it would be possible to get background images by aggregation of areas not get into bounding boxes.\n",
    "But in most videos we can see serious fluctuations of camera due to wind, so it is impossible to get clear background image by simple aggregation of video frames.\n",
    "In such case warping several frames with help of optical flow could be useful for background estimation.\n",
    "\n",
    "\n",
    "2. <b>Unsupervised segmentation based on CNNs and classical methods like Super Pixel, GrabCut and other. </b>\n",
    "There are some CNNs approaches (https://paperswithcode.com/task/unsupervised-semantic-segmentation), needs deeper investigation.\n",
    "And several approaches of unsupervised segmentation using GrabCut and similar techniques (e.g. https://josephkj.in/projects/MASON/).\n",
    "They require a pre-trained model for object detection.\n",
    "The segmentation can be presented in bounding boxes and pixel labels are also could be taken from predicted bbox classes.\n",
    "\n",
    "3. <b>Pretraining on other dataset.</b>\n",
    "Similar datasets overview provided in similar_datasets_overview.ipynb.\n",
    "The most suitable datasets are marked with the [Good] tag.\n",
    "Despite there's some number of similar datasets all of them rather small and none of them has 'biker' class.\n",
    "\n",
    "1st and 2nd approaches could be used either for annotation training data or for direct inference.\n",
    "There is one important drawback of these two approaches - they suffer much from strong shadows which could be considered as segmented area.\n",
    "Also in case of usage retrieved segmentations as training data it is needed to implement segmentation model as like for approach #3.\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}